# -*- coding: utf-8 -*-
#pip install langchain langchain-community faiss-cpu python-docx pypdf dashscope sentence-transformers
from core.data_loader import load_special_document, create_documents_from_sections
from core.text_splitter import split_policy_documents
from core.embeddings import get_embeddings
from core.vectorstore import build_vectorstore
from core.llm import LLMClient
from core.prompts import get_prompt_template
from core.parallel import process_files_concurrently, process_queries_concurrently
from core.qa_chain import create_qa_chain
from config import config
import os

def main():
    try:
        # ================== ç¯å¢ƒå˜é‡å‡†å¤‡é˜¶æ®µ ==================
        # ç¯å¢ƒå˜é‡æ ¡éªŒ
        if not config.DASHSCOPE_API_KEY:
            raise ValueError("æœªæ‰¾åˆ° DASHSCOPE_API_KEYï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡")

        # ================== æ•°æ®å¤„ç†é˜¶æ®µ ==================
        # åŠ è½½å¹¶å¤„ç†æ³•å¾‹æ–‡æ¡£
        print("\n[é˜¶æ®µ1] æ­£åœ¨åŠ è½½æ ¸å¿ƒæ³•å¾‹æ–‡æ¡£...")
        raw_text = load_special_document("laws.txt")
        policy_sections = split_policy_documents(raw_text)
        legal_docs = create_documents_from_sections(policy_sections)
        print(f"â†’ æˆåŠŸåŠ è½½ {len(legal_docs)} æ¡æ³•å¾‹æ¡æ¬¾")

        # åˆå§‹åŒ– Embedding æ¨¡å‹
        print("\n[é˜¶æ®µ2] æ­£åœ¨åˆå§‹åŒ–è¯­ä¹‰åµŒå…¥æ¨¡å‹...")
        embeddings = get_embeddings()

        # æ„å»ºå‘é‡æ•°æ®åº“
        print("\n[é˜¶æ®µ3] æ­£åœ¨æ„å»ºæ³•å¾‹çŸ¥è¯†å‘é‡åº“...")
        vectorstore = build_vectorstore(legal_docs)
        print(f"â†’ å‘é‡åº“å·²åŒ…å« {vectorstore.index.ntotal} ä¸ªå‘é‡")

        # ================== æ¨¡å‹å‡†å¤‡é˜¶æ®µ ==================
        # åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹
        print("\n[é˜¶æ®µ4] æ­£åœ¨åˆå§‹åŒ–é€šä¹‰åƒé—®å¤§æ¨¡å‹...")
        llm_client = LLMClient()
        
        # å‡†å¤‡ Prompt æ¨¡æ¿
        print("\n[é˜¶æ®µ5] æ­£åœ¨åŠ è½½æç¤ºè¯æ¨¡æ¿...")
        prompt = get_prompt_template()

        # æ„å»º QA é“¾
        print("\n[é˜¶æ®µ6] æ­£åœ¨æ„å»ºæ™ºèƒ½é—®ç­”é“¾...")
        qa_chain = create_qa_chain(
            vectorstore=vectorstore,
            llm=llm_client.get_client(),
            prompt=prompt
        )

        # ================== é—®ç­”å¤„ç†é˜¶æ®µ ==================
        # è¯»å–ç”¨æˆ·é—®é¢˜æ–‡ä»¶
        print("\n" + "="*30 + " å¼€å§‹å¤„ç†ç”¨æˆ·é—®é¢˜ " + "="*30)
        print("\n[é˜¶æ®µ7] æ­£åœ¨æ‰«æå¹¶è§£æç”¨æˆ·é—®é¢˜æ–‡ä»¶...")
        all_queries = []
        for chunks in process_files_concurrently():
            all_queries.extend(chunks)
        print(f"â†’ å…±å‘ç° {len(all_queries)} æ¡å¾…å¤„ç†é—®é¢˜")

        # å¹¶è¡Œå¤„ç†é—®ç­”
        print("\n[é˜¶æ®µ8] å¯åŠ¨å¹¶è¡Œæ¨ç†å¼•æ“...")
        results = process_queries_concurrently(qa_chain, all_queries)

        # ================== ç»“æœè¾“å‡ºé˜¶æ®µ ==================
        print("\n" + "="*30 + " æœ€ç»ˆæ¨ç†ç»“æœ " + "="*30)
        for idx, item in enumerate(results, 1):
            print(f"\nğŸ” é—®é¢˜ {idx}/{len(results)}")
            print(f"â“ {item['question']}")
            print(f"ğŸ“ å›ç­”ï¼š\n{item['result']}")
            print("-" * 60)

    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿè¿è¡Œå¼‚å¸¸: {str(e)}")
        if isinstance(e, KeyboardInterrupt):
            print("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    finally:
        print("\nâœ… ç³»ç»Ÿè¿è¡Œå®Œæˆ")

if __name__ == "__main__":
    # è®¾ç½®ç»ˆç«¯ç¼–ç æ”¯æŒä¸­æ–‡
    import sys
    if sys.stdout.encoding != 'UTF-8':
        sys.stdout.reconfigure(encoding='utf-8')
    main()