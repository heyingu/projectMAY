{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是对这段代码的**逐行详细解释**，包括每个模块的功能、使用的技术以及背后的逻辑。\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 1. 编码声明\n",
    "\n",
    "```python\n",
    "# -*- coding: utf-8 -*-\n",
    "```\n",
    "\n",
    "- **作用**：指定文件的编码格式为 UTF-8。\n",
    "- **说明**：确保中文字符在 Python 中不会出现解码错误。\n",
    "\n",
    "---\n",
    "\n",
    "## 📦 2. 导入依赖库\n",
    "\n",
    "```python\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.llms import Tongyi\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "```\n",
    "\n",
    "| 模块 | 功能 |\n",
    "|------|------|\n",
    "| `os` | 操作系统接口，用于设置环境变量（如 API Key） |\n",
    "| `TextLoader` | 加载 `.txt` 纯文本文件作为文档 |\n",
    "| `CharacterTextSplitter` | 将长文档按字符切分为小段 |\n",
    "| `HuggingFaceEmbeddings` | 使用 Hugging Face 的模型生成文本嵌入向量 |\n",
    "| `FAISS` | Facebook AI 提供的高效相似性搜索库，用于构建向量数据库 |\n",
    "| `Tongyi` | 阿里通义千问的大语言模型接口 |\n",
    "| `PromptTemplate` | 定义提示词模板，用于 LLM 输入 |\n",
    "| `RetrievalQA` | 构建检索增强问答链 |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 3. 函数定义部分\n",
    "\n",
    "### ✅ 3.1 加载并切分文档\n",
    "\n",
    "```python\n",
    "def load_and_split_documents(file_path=\"laws.txt\"):\n",
    "    loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "```\n",
    "\n",
    "- **功能**：读取法律条文文本文件，并将其分割成适合处理的小块。\n",
    "- **参数说明**：\n",
    "  - `chunk_size=300`：每块最多包含 300 个字符\n",
    "  - `chunk_overlap=50`：相邻块之间有 50 个字符重叠，避免信息断层\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3.2 初始化 Embedding 模型\n",
    "\n",
    "```python\n",
    "def get_embeddings():\n",
    "    model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return embeddings\n",
    "```\n",
    "\n",
    "- **功能**：加载一个多语言句子级语义相似度模型。\n",
    "- **模型特点**：\n",
    "  - 支持多种语言（包括中文）\n",
    "  - 可以将文本转换为固定维度的向量，用于语义检索\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3.3 构建向量数据库\n",
    "\n",
    "```python\n",
    "def build_vectorstore(docs, embeddings):\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    return vectorstore\n",
    "```\n",
    "\n",
    "- **功能**：将切分后的文档通过 Embedding 模型转化为向量，存入 FAISS 数据库中。\n",
    "- **用途**：后续进行语义检索时，可以快速找到最相关的文档片段\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3.4 初始化 Qwen 大语言模型\n",
    "\n",
    "```python\n",
    "def get_llm(api_key):\n",
    "    llm = Tongyi(model_name=\"qwen-max\", dashscope_api_key=api_key)\n",
    "    return llm\n",
    "```\n",
    "\n",
    "- **功能**：连接阿里云 DashScope 平台的 Qwen 模型服务。\n",
    "- **模型说明**：\n",
    "  - `qwen-max` 是一个性能较强的推理模型\n",
    "  - 需要提供合法的 API Key 才能调用\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3.5 定义 Prompt 模板\n",
    "\n",
    "```python\n",
    "def get_prompt_template():\n",
    "    template = \"\"\"用户问题：{question}\n",
    "\n",
    "相关法律条文：{context}\n",
    "\n",
    "请简要判断该政策是否违反公平竞争原则，并说明依据：\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])\n",
    "    return prompt\n",
    "```\n",
    "\n",
    "- **功能**：定义大模型回答问题的输入模板。\n",
    "- **变量说明**：\n",
    "  - `{question}`：用户的问题\n",
    "  - `{context}`：从 FAISS 中检索到的相关法律条文\n",
    "- **用途**：引导模型结合上下文进行合规性判断\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3.6 构建 QA 链\n",
    "\n",
    "```python\n",
    "def build_qa_chain(vectorstore, llm, prompt):\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "    return qa_chain\n",
    "```\n",
    "\n",
    "- **功能**：构建一个完整的 RAG（Retrieval-Augmented Generation）流程。\n",
    "- **关键组件**：\n",
    "  - `retriever`：从 FAISS 中检索 Top-K（这里是 2 条）最相关的文档\n",
    "  - `chain_type=\"stuff\"`：表示将所有检索结果合并后传给 LLM\n",
    "  - `prompt`：前面定义的提示词模板\n",
    "\n",
    "---\n",
    "\n",
    "## 🏁 4. 主函数入口\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    # 设置 DashScope API Key\n",
    "    DASHSCOPE_API_KEY = \"sk-7fb2aee47f5d4531855a7ac3412249fe\"  # 替换为你的实际 API Key\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = DASHSCOPE_API_KEY\n",
    "```\n",
    "\n",
    "- **功能**：设置阿里云平台 API Key，以便调用 Qwen 接口。\n",
    "\n",
    "---\n",
    "\n",
    "### 步骤执行流程\n",
    "\n",
    "```python\n",
    "    # 步骤 1：加载并切分文档\n",
    "    print(\"正在加载并切分文档...\")\n",
    "    docs = load_and_split_documents()\n",
    "\n",
    "    # 步骤 2：初始化 Embedding 模型\n",
    "    print(\"正在加载 Embedding 模型...\")\n",
    "    embeddings = get_embeddings()\n",
    "\n",
    "    # 步骤 3：构建 FAISS 向量数据库\n",
    "    print(\"正在构建向量数据库...\")\n",
    "    vectorstore = build_vectorstore(docs, embeddings)\n",
    "\n",
    "    # 步骤 4：初始化 LLM\n",
    "    print(\"正在加载 Qwen 模型...\")\n",
    "    llm = get_llm(DASHSCOPE_API_KEY)\n",
    "\n",
    "    # 步骤 5：定义 Prompt 模板\n",
    "    print(\"正在构建 Prompt 模板...\")\n",
    "    prompt = get_prompt_template()\n",
    "\n",
    "    # 步骤 6：构建 QA 链\n",
    "    print(\"正在整合 RetrievalQA 链...\")\n",
    "    qa_chain = build_qa_chain(vectorstore, llm, prompt)\n",
    "```\n",
    "\n",
    "- **流程说明**：\n",
    "  - 文档加载 → 切片 → 嵌入 → 向量化 → LLM 加载 → 提示词模板 → 构建问答链\n",
    "\n",
    "---\n",
    "\n",
    "### 示例查询与推理\n",
    "\n",
    "```python\n",
    "    # 示例查询\n",
    "    query = \"某地出台政策，要求外地企业必须在本地设立分支机构才能参与政府采购，是否合规？\"\n",
    "\n",
    "    print(\"\\n开始推理...\\n\")\n",
    "    result = qa_chain.run(query)\n",
    "\n",
    "    print(\"回答结果：\")\n",
    "    print(result)\n",
    "```\n",
    "\n",
    "- **功能**：对一个具体的政策问题进行推理和判断。\n",
    "- **输出**：模型根据检索到的相关法律条文，给出是否符合公平竞争原则的判断。\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 整体架构图（RAG 流程）\n",
    "\n",
    "```\n",
    "[Query] \n",
    "   ↓\n",
    "[Retriever (FAISS)] → 检索 Top-K 相关文档\n",
    "   ↓\n",
    "[Prompt Template] → 构造完整输入\n",
    "   ↓\n",
    "[LLM (Qwen)] → 生成答案\n",
    "   ↓\n",
    "[Answer]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结\n",
    "\n",
    "| 模块 | 技术 | 功能 |\n",
    "|------|------|------|\n",
    "| 文档处理 | TextLoader + CharacterTextSplitter | 加载并切分原始法律条文 |\n",
    "| 向量化 | HuggingFaceEmbeddings + FAISS | 构建可检索的语义数据库 |\n",
    "| 模型推理 | Tongyi (Qwen) | 回答合规性问题 |\n",
    "| 提示工程 | PromptTemplate | 控制输出格式和逻辑 |\n",
    "| 问答链 | RetrievalQA | 集成检索+生成能力 |\n",
    "\n",
    "---\n",
    "\n",
    "如果你需要我进一步解释某个模块或改造成 Web 应用、多轮对话等，请告诉我！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
