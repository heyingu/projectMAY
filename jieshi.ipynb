{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸‹é¢æ˜¯å¯¹è¿™æ®µä»£ç çš„**é€è¡Œè¯¦ç»†è§£é‡Š**ï¼ŒåŒ…æ‹¬æ¯ä¸ªæ¨¡å—çš„åŠŸèƒ½ã€ä½¿ç”¨çš„æŠ€æœ¯ä»¥åŠèƒŒåçš„é€»è¾‘ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ 1. ç¼–ç å£°æ˜\n",
    "\n",
    "```python\n",
    "# -*- coding: utf-8 -*-\n",
    "```\n",
    "\n",
    "- **ä½œç”¨**ï¼šæŒ‡å®šæ–‡ä»¶çš„ç¼–ç æ ¼å¼ä¸º UTF-8ã€‚\n",
    "- **è¯´æ˜**ï¼šç¡®ä¿ä¸­æ–‡å­—ç¬¦åœ¨ Python ä¸­ä¸ä¼šå‡ºç°è§£ç é”™è¯¯ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“¦ 2. å¯¼å…¥ä¾èµ–åº“\n",
    "\n",
    "```python\n",
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.llms import Tongyi\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "```\n",
    "\n",
    "| æ¨¡å— | åŠŸèƒ½ |\n",
    "|------|------|\n",
    "| `os` | æ“ä½œç³»ç»Ÿæ¥å£ï¼Œç”¨äºè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚ API Keyï¼‰ |\n",
    "| `TextLoader` | åŠ è½½ `.txt` çº¯æ–‡æœ¬æ–‡ä»¶ä½œä¸ºæ–‡æ¡£ |\n",
    "| `CharacterTextSplitter` | å°†é•¿æ–‡æ¡£æŒ‰å­—ç¬¦åˆ‡åˆ†ä¸ºå°æ®µ |\n",
    "| `HuggingFaceEmbeddings` | ä½¿ç”¨ Hugging Face çš„æ¨¡å‹ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡ |\n",
    "| `FAISS` | Facebook AI æä¾›çš„é«˜æ•ˆç›¸ä¼¼æ€§æœç´¢åº“ï¼Œç”¨äºæ„å»ºå‘é‡æ•°æ®åº“ |\n",
    "| `Tongyi` | é˜¿é‡Œé€šä¹‰åƒé—®çš„å¤§è¯­è¨€æ¨¡å‹æ¥å£ |\n",
    "| `PromptTemplate` | å®šä¹‰æç¤ºè¯æ¨¡æ¿ï¼Œç”¨äº LLM è¾“å…¥ |\n",
    "| `RetrievalQA` | æ„å»ºæ£€ç´¢å¢å¼ºé—®ç­”é“¾ |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” 3. å‡½æ•°å®šä¹‰éƒ¨åˆ†\n",
    "\n",
    "### âœ… 3.1 åŠ è½½å¹¶åˆ‡åˆ†æ–‡æ¡£\n",
    "\n",
    "```python\n",
    "def load_and_split_documents(file_path=\"laws.txt\"):\n",
    "    loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "```\n",
    "\n",
    "- **åŠŸèƒ½**ï¼šè¯»å–æ³•å¾‹æ¡æ–‡æ–‡æœ¬æ–‡ä»¶ï¼Œå¹¶å°†å…¶åˆ†å‰²æˆé€‚åˆå¤„ç†çš„å°å—ã€‚\n",
    "- **å‚æ•°è¯´æ˜**ï¼š\n",
    "  - `chunk_size=300`ï¼šæ¯å—æœ€å¤šåŒ…å« 300 ä¸ªå­—ç¬¦\n",
    "  - `chunk_overlap=50`ï¼šç›¸é‚»å—ä¹‹é—´æœ‰ 50 ä¸ªå­—ç¬¦é‡å ï¼Œé¿å…ä¿¡æ¯æ–­å±‚\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 3.2 åˆå§‹åŒ– Embedding æ¨¡å‹\n",
    "\n",
    "```python\n",
    "def get_embeddings():\n",
    "    model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return embeddings\n",
    "```\n",
    "\n",
    "- **åŠŸèƒ½**ï¼šåŠ è½½ä¸€ä¸ªå¤šè¯­è¨€å¥å­çº§è¯­ä¹‰ç›¸ä¼¼åº¦æ¨¡å‹ã€‚\n",
    "- **æ¨¡å‹ç‰¹ç‚¹**ï¼š\n",
    "  - æ”¯æŒå¤šç§è¯­è¨€ï¼ˆåŒ…æ‹¬ä¸­æ–‡ï¼‰\n",
    "  - å¯ä»¥å°†æ–‡æœ¬è½¬æ¢ä¸ºå›ºå®šç»´åº¦çš„å‘é‡ï¼Œç”¨äºè¯­ä¹‰æ£€ç´¢\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 3.3 æ„å»ºå‘é‡æ•°æ®åº“\n",
    "\n",
    "```python\n",
    "def build_vectorstore(docs, embeddings):\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    return vectorstore\n",
    "```\n",
    "\n",
    "- **åŠŸèƒ½**ï¼šå°†åˆ‡åˆ†åçš„æ–‡æ¡£é€šè¿‡ Embedding æ¨¡å‹è½¬åŒ–ä¸ºå‘é‡ï¼Œå­˜å…¥ FAISS æ•°æ®åº“ä¸­ã€‚\n",
    "- **ç”¨é€”**ï¼šåç»­è¿›è¡Œè¯­ä¹‰æ£€ç´¢æ—¶ï¼Œå¯ä»¥å¿«é€Ÿæ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 3.4 åˆå§‹åŒ– Qwen å¤§è¯­è¨€æ¨¡å‹\n",
    "\n",
    "```python\n",
    "def get_llm(api_key):\n",
    "    llm = Tongyi(model_name=\"qwen-max\", dashscope_api_key=api_key)\n",
    "    return llm\n",
    "```\n",
    "\n",
    "- **åŠŸèƒ½**ï¼šè¿æ¥é˜¿é‡Œäº‘ DashScope å¹³å°çš„ Qwen æ¨¡å‹æœåŠ¡ã€‚\n",
    "- **æ¨¡å‹è¯´æ˜**ï¼š\n",
    "  - `qwen-max` æ˜¯ä¸€ä¸ªæ€§èƒ½è¾ƒå¼ºçš„æ¨ç†æ¨¡å‹\n",
    "  - éœ€è¦æä¾›åˆæ³•çš„ API Key æ‰èƒ½è°ƒç”¨\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 3.5 å®šä¹‰ Prompt æ¨¡æ¿\n",
    "\n",
    "```python\n",
    "def get_prompt_template():\n",
    "    template = \"\"\"ç”¨æˆ·é—®é¢˜ï¼š{question}\n",
    "\n",
    "ç›¸å…³æ³•å¾‹æ¡æ–‡ï¼š{context}\n",
    "\n",
    "è¯·ç®€è¦åˆ¤æ–­è¯¥æ”¿ç­–æ˜¯å¦è¿åå…¬å¹³ç«äº‰åŸåˆ™ï¼Œå¹¶è¯´æ˜ä¾æ®ï¼š\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])\n",
    "    return prompt\n",
    "```\n",
    "\n",
    "- **åŠŸèƒ½**ï¼šå®šä¹‰å¤§æ¨¡å‹å›ç­”é—®é¢˜çš„è¾“å…¥æ¨¡æ¿ã€‚\n",
    "- **å˜é‡è¯´æ˜**ï¼š\n",
    "  - `{question}`ï¼šç”¨æˆ·çš„é—®é¢˜\n",
    "  - `{context}`ï¼šä» FAISS ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³æ³•å¾‹æ¡æ–‡\n",
    "- **ç”¨é€”**ï¼šå¼•å¯¼æ¨¡å‹ç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œåˆè§„æ€§åˆ¤æ–­\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… 3.6 æ„å»º QA é“¾\n",
    "\n",
    "```python\n",
    "def build_qa_chain(vectorstore, llm, prompt):\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2}),\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "    return qa_chain\n",
    "```\n",
    "\n",
    "- **åŠŸèƒ½**ï¼šæ„å»ºä¸€ä¸ªå®Œæ•´çš„ RAGï¼ˆRetrieval-Augmented Generationï¼‰æµç¨‹ã€‚\n",
    "- **å…³é”®ç»„ä»¶**ï¼š\n",
    "  - `retriever`ï¼šä» FAISS ä¸­æ£€ç´¢ Top-Kï¼ˆè¿™é‡Œæ˜¯ 2 æ¡ï¼‰æœ€ç›¸å…³çš„æ–‡æ¡£\n",
    "  - `chain_type=\"stuff\"`ï¼šè¡¨ç¤ºå°†æ‰€æœ‰æ£€ç´¢ç»“æœåˆå¹¶åä¼ ç»™ LLM\n",
    "  - `prompt`ï¼šå‰é¢å®šä¹‰çš„æç¤ºè¯æ¨¡æ¿\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ 4. ä¸»å‡½æ•°å…¥å£\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    # è®¾ç½® DashScope API Key\n",
    "    DASHSCOPE_API_KEY = \"sk-7fb2aee47f5d4531855a7ac3412249fe\"  # æ›¿æ¢ä¸ºä½ çš„å®é™… API Key\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = DASHSCOPE_API_KEY\n",
    "```\n",
    "\n",
    "- **åŠŸèƒ½**ï¼šè®¾ç½®é˜¿é‡Œäº‘å¹³å° API Keyï¼Œä»¥ä¾¿è°ƒç”¨ Qwen æ¥å£ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### æ­¥éª¤æ‰§è¡Œæµç¨‹\n",
    "\n",
    "```python\n",
    "    # æ­¥éª¤ 1ï¼šåŠ è½½å¹¶åˆ‡åˆ†æ–‡æ¡£\n",
    "    print(\"æ­£åœ¨åŠ è½½å¹¶åˆ‡åˆ†æ–‡æ¡£...\")\n",
    "    docs = load_and_split_documents()\n",
    "\n",
    "    # æ­¥éª¤ 2ï¼šåˆå§‹åŒ– Embedding æ¨¡å‹\n",
    "    print(\"æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹...\")\n",
    "    embeddings = get_embeddings()\n",
    "\n",
    "    # æ­¥éª¤ 3ï¼šæ„å»º FAISS å‘é‡æ•°æ®åº“\n",
    "    print(\"æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“...\")\n",
    "    vectorstore = build_vectorstore(docs, embeddings)\n",
    "\n",
    "    # æ­¥éª¤ 4ï¼šåˆå§‹åŒ– LLM\n",
    "    print(\"æ­£åœ¨åŠ è½½ Qwen æ¨¡å‹...\")\n",
    "    llm = get_llm(DASHSCOPE_API_KEY)\n",
    "\n",
    "    # æ­¥éª¤ 5ï¼šå®šä¹‰ Prompt æ¨¡æ¿\n",
    "    print(\"æ­£åœ¨æ„å»º Prompt æ¨¡æ¿...\")\n",
    "    prompt = get_prompt_template()\n",
    "\n",
    "    # æ­¥éª¤ 6ï¼šæ„å»º QA é“¾\n",
    "    print(\"æ­£åœ¨æ•´åˆ RetrievalQA é“¾...\")\n",
    "    qa_chain = build_qa_chain(vectorstore, llm, prompt)\n",
    "```\n",
    "\n",
    "- **æµç¨‹è¯´æ˜**ï¼š\n",
    "  - æ–‡æ¡£åŠ è½½ â†’ åˆ‡ç‰‡ â†’ åµŒå…¥ â†’ å‘é‡åŒ– â†’ LLM åŠ è½½ â†’ æç¤ºè¯æ¨¡æ¿ â†’ æ„å»ºé—®ç­”é“¾\n",
    "\n",
    "---\n",
    "\n",
    "### ç¤ºä¾‹æŸ¥è¯¢ä¸æ¨ç†\n",
    "\n",
    "```python\n",
    "    # ç¤ºä¾‹æŸ¥è¯¢\n",
    "    query = \"æŸåœ°å‡ºå°æ”¿ç­–ï¼Œè¦æ±‚å¤–åœ°ä¼ä¸šå¿…é¡»åœ¨æœ¬åœ°è®¾ç«‹åˆ†æ”¯æœºæ„æ‰èƒ½å‚ä¸æ”¿åºœé‡‡è´­ï¼Œæ˜¯å¦åˆè§„ï¼Ÿ\"\n",
    "\n",
    "    print(\"\\nå¼€å§‹æ¨ç†...\\n\")\n",
    "    result = qa_chain.run(query)\n",
    "\n",
    "    print(\"å›ç­”ç»“æœï¼š\")\n",
    "    print(result)\n",
    "```\n",
    "\n",
    "- **åŠŸèƒ½**ï¼šå¯¹ä¸€ä¸ªå…·ä½“çš„æ”¿ç­–é—®é¢˜è¿›è¡Œæ¨ç†å’Œåˆ¤æ–­ã€‚\n",
    "- **è¾“å‡º**ï¼šæ¨¡å‹æ ¹æ®æ£€ç´¢åˆ°çš„ç›¸å…³æ³•å¾‹æ¡æ–‡ï¼Œç»™å‡ºæ˜¯å¦ç¬¦åˆå…¬å¹³ç«äº‰åŸåˆ™çš„åˆ¤æ–­ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  æ•´ä½“æ¶æ„å›¾ï¼ˆRAG æµç¨‹ï¼‰\n",
    "\n",
    "```\n",
    "[Query] \n",
    "   â†“\n",
    "[Retriever (FAISS)] â†’ æ£€ç´¢ Top-K ç›¸å…³æ–‡æ¡£\n",
    "   â†“\n",
    "[Prompt Template] â†’ æ„é€ å®Œæ•´è¾“å…¥\n",
    "   â†“\n",
    "[LLM (Qwen)] â†’ ç”Ÿæˆç­”æ¡ˆ\n",
    "   â†“\n",
    "[Answer]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… æ€»ç»“\n",
    "\n",
    "| æ¨¡å— | æŠ€æœ¯ | åŠŸèƒ½ |\n",
    "|------|------|------|\n",
    "| æ–‡æ¡£å¤„ç† | TextLoader + CharacterTextSplitter | åŠ è½½å¹¶åˆ‡åˆ†åŸå§‹æ³•å¾‹æ¡æ–‡ |\n",
    "| å‘é‡åŒ– | HuggingFaceEmbeddings + FAISS | æ„å»ºå¯æ£€ç´¢çš„è¯­ä¹‰æ•°æ®åº“ |\n",
    "| æ¨¡å‹æ¨ç† | Tongyi (Qwen) | å›ç­”åˆè§„æ€§é—®é¢˜ |\n",
    "| æç¤ºå·¥ç¨‹ | PromptTemplate | æ§åˆ¶è¾“å‡ºæ ¼å¼å’Œé€»è¾‘ |\n",
    "| é—®ç­”é“¾ | RetrievalQA | é›†æˆæ£€ç´¢+ç”Ÿæˆèƒ½åŠ› |\n",
    "\n",
    "---\n",
    "\n",
    "å¦‚æœä½ éœ€è¦æˆ‘è¿›ä¸€æ­¥è§£é‡ŠæŸä¸ªæ¨¡å—æˆ–æ”¹é€ æˆ Web åº”ç”¨ã€å¤šè½®å¯¹è¯ç­‰ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
